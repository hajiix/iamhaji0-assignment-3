{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245217cc",
   "metadata": {},
   "source": [
    "# Assignment: SVD Preprocessing on MNIST with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffa444",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "In this assignment, you will apply **Singular Value Decomposition (SVD)** as a preprocessing step to the **MNIST dataset** and train a **logistic regression classifier**. You will compare the model performance and training time when using different levels of SVD for dimensionality reduction.\n",
    "\n",
    "In this assignment, you will need to:\n",
    "1. Load the MNIST dataset and normalize it.\n",
    "2. Perform SVD and reduce the dimensions of the data.\n",
    "3. Train a logistic regression model on the original and SVD-reduced data.\n",
    "4. Measure and compare the training time and accuracy of the model with varying SVD components.\n",
    "5. Plot the results and analyze how SVD impacts the performance and efficiency of the model.\n",
    "\n",
    "***\n",
    "Your tasks include:\n",
    "1. Implement SVD algorithm. You are not allowed to directly use SVD implemented by other packages, but you may use functions in NumPy. (Part 2)\n",
    "2. Explore the accuracy and time performance from different numbers of SVD components. (Part 4)\n",
    "3. Visualize the accuracy, time performance and top 5 singular vectors in the dataset, analyze and explain which number of SVD component looks best to you? (Part 4,5&6) Hint: singular vectors should be reshaped to 28x28 images for visualization.\n",
    "***\n",
    "**Note that you may not import any other function or package.** Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e10cb3",
   "metadata": {},
   "source": [
    "## Part 1: Load the MNIST dataset and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f2d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "x:         pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
      "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0           0.0       0.0       0.0       0.0       0.0  \n",
      "1           0.0       0.0       0.0       0.0       0.0  \n",
      "2           0.0       0.0       0.0       0.0       0.0  \n",
      "3           0.0       0.0       0.0       0.0       0.0  \n",
      "4           0.0       0.0       0.0       0.0       0.0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "69995       0.0       0.0       0.0       0.0       0.0  \n",
      "69996       0.0       0.0       0.0       0.0       0.0  \n",
      "69997       0.0       0.0       0.0       0.0       0.0  \n",
      "69998       0.0       0.0       0.0       0.0       0.0  \n",
      "69999       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[70000 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, parser=\"auto\")\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Normalize the data\n",
    "X = X / 255.0\n",
    "print(\"x: \", X)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8572d",
   "metadata": {},
   "source": [
    "## Part 2: Implement SVD for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eaaad8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bd59f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     X_test_reduced \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(U_test_eigenvectors, np\u001b[38;5;241m.\u001b[39mdot(sigma_test, V_test_eigenvectors\u001b[38;5;241m.\u001b[39mT))\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(X_train_reduced, X_test_reduced)\n\u001b[0;32m---> 57\u001b[0m apply_svd_custom(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m]]), np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def apply_svd_custom(X_train, X_test, n_components):\n",
    "    # Multiply transposes\n",
    "    V_train, V_test = np.dot(X_train.T, X_train), np.dot(X_test.T, X_test)\n",
    "    U_train, U_test = np.dot(X_train, X_train.T), np.dot(X_test, X_test.T)\n",
    "\n",
    "    # Find eigenvalues and eigenvectors\n",
    "    V_train_eigenvalues, V_train_eigenvectors = np.linalg.eig(V_train)\n",
    "    V_test_eigenvalues, V_test_eigenvectors = np.linalg.eig(V_test)\n",
    "\n",
    "    U_train_eigenvalues, U_train_eigenvectors = np.linalg.eig(U_train)\n",
    "    U_test_eigenvalues, U_test_eigenvectors = np.linalg.eig(U_test)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors\n",
    "    sorted_indices_train, sorted_indices_test = V_train_eigenvalues.argsort()[::-1], V_test_eigenvalues.argsort()[::-1]\n",
    "    V_train_eigenvalues, V_test_eigenvalues = V_train_eigenvalues[sorted_indices_train], V_test_eigenvalues[sorted_indices_test]\n",
    "    V_train_eigenvectors, V_test_eigenvectors = V_train_eigenvectors[:, sorted_indices_train], V_test_eigenvectors[:, sorted_indices_test]\n",
    "\n",
    "    sorted_indices_train, sorted_indices_test = U_train_eigenvalues.argsort()[::-1], U_test_eigenvalues.argsort()[::-1]\n",
    "    U_train_eigenvalues, U_test_eigenvalues = U_train_eigenvalues[sorted_indices_train], U_test_eigenvalues[sorted_indices_test]\n",
    "    U_train_eigenvectors, U_test_eigenvectors = U_train_eigenvectors[:, sorted_indices_train], U_test_eigenvectors[:, sorted_indices_test]\n",
    "\n",
    "    # Find Sqrt of eigenvalues to find singular value\n",
    "    for index, value in enumerate(V_train_eigenvalues):\n",
    "        V_train_eigenvalues[index] = np.sqrt(np.abs(value))\n",
    "    for index, value in enumerate(V_test_eigenvalues):\n",
    "        V_test_eigenvalues[index] = np.sqrt(np.abs(value))\n",
    "\n",
    "    # Create Sigma\n",
    "    sigma_train, sigma_test = np.diag(V_train_eigenvalues), np.diag(V_test_eigenvalues)\n",
    "\n",
    "    U_train_eigenvectors = U_train_eigenvectors[:, :n_components]\n",
    "    V_train_eigenvectors = V_train_eigenvectors[:, :n_components]\n",
    "    sigma_train = sigma_train[:n_components, :]\n",
    "\n",
    "    U_test_eigenvectors = U_test_eigenvectors[:, :n_components]\n",
    "    V_test_eigenvectors = V_test_eigenvectors[:, :n_components]\n",
    "    sigma_test = sigma_test[:n_components, :]\n",
    "\n",
    "    for row in range(len(U_train_eigenvectors[0])):\n",
    "        magnitude = np.linalg.norm(U_train_eigenvectors[:, row])\n",
    "        if np.isnan(magnitude) or magnitude == 0:\n",
    "            U_train_eigenvectors[:, row] = 0\n",
    "        else:\n",
    "            U_train_eigenvectors[:, row] *= (1 / magnitude)\n",
    "\n",
    "    for row in range(len(U_test_eigenvectors[0])):\n",
    "        magnitude = np.linalg.norm(U_test_eigenvectors[:, row])\n",
    "        if np.isnan(magnitude) or magnitude == 0:\n",
    "            U_test_eigenvectors[:, row] = 0\n",
    "        else:\n",
    "            U_test_eigenvectors[:, row] *= (1 / magnitude)\n",
    "\n",
    "    X_train_reduced = np.dot(U_train_eigenvectors, np.dot(sigma_train, V_train_eigenvectors.T))\n",
    "    X_test_reduced = np.dot(U_test_eigenvectors, np.dot(sigma_test, V_test_eigenvectors.T))\n",
    "\n",
    "    return(X_train_reduced, X_test_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a7a9d",
   "metadata": {},
   "source": [
    "## Part 3: Train Logistic Regression and Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfc0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train logistic regression and track training time\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    model = LogisticRegression(max_iter=1000, solver='saga', random_state=42, multi_class='multinomial')\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e557a05",
   "metadata": {},
   "source": [
    "## Part 4: Experiment with Different Levels of SVD\n",
    "\n",
    "Now, apply SVD with varying numbers of components and observe how the dimensionality reduction impacts the model's performance. Record both the accuracy and training time for each number of components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a460725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models with different levels of SVD preprocessing...\n",
      "Applying custom SVD with 1 components...\n"
     ]
    }
   ],
   "source": [
    "svd_components = [1]  # You need to decide what number to search...\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "\n",
    "print(\"Training models with different levels of SVD preprocessing...\")\n",
    "for n_components in svd_components:\n",
    "    print(f\"Applying custom SVD with {n_components} components...\")\n",
    "    \n",
    "    # Apply SVD to the training and test sets\n",
    "    # Call apply_svd_custom() here...\n",
    "    X_train_svd, X_test_svd = apply_svd_custom(X_train=X_train, X_test=X_test, n_components=n_components)\n",
    "    y_train, y_test = apply_svd_custom(X_train=y_train, X_test=y_test, n_components=n_components)\n",
    "    print(\"done with apply_svd_custom\")\n",
    "    # Train the logistic regression model and get accuracy and training time\n",
    "    accuracy, training_time = train_logistic_regression(X_train_svd, y_train, X_test_svd, y_test)\n",
    "        \n",
    "    print(f\"SVD components: {n_components}, Accuracy: {accuracy:.4f}, Training time: {training_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7aca12",
   "metadata": {},
   "source": [
    "## Part 5: Visualize and Analyze the Results\n",
    "\n",
    "Finally, plot the accuracy, training time as a function of the number of SVD components, and top 5 singular vectors. This will help you understand the trade-off between dimensionality reduction, accuracy, and model training time, and how SVD generally works. Hint: singular vectors should be reshaped to 28x28 images for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your implementation here...\n",
    "## You may add necessary lines in Part 4 to access data for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210569a",
   "metadata": {},
   "source": [
    "## Part 6: Analyze / Conclusion \n",
    "\n",
    "YOUR ANSWER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f043c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
